{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "from math import ceil\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: No GPU found. Please use a GPU to train your neural network.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 1242, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 1242, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 576, 3)\n"
     ]
    }
   ],
   "source": [
    "#To check the shape of the output image\n",
    "image_file = os.path.join('runs', 'um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check the label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n",
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n",
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 576, 3)\n",
      "(160, 576, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159e84a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "background_color = np.array([255, 0, 0])\n",
    "\n",
    "image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "gt_image_file = os.path.join(data_dir, 'data_road/training/gt_image_2/um_lane_000000.png')\n",
    "\n",
    "image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
    "\n",
    "gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "print(np.shape(image))\n",
    "print(np.shape(gt_image))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.imshow(image)\n",
    "    \n",
    "plt.subplot(132)\n",
    "plt.imshow(gt_image[:,:,0],cmap='gray')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(gt_image[:,:,1],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here starts the actual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights\n",
    "    vgg_tag = 'vgg16'\n",
    "    tf.saved_model.loader.load(sess,[vgg_tag],vgg_path)\n",
    "    \n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    #graph = tf.Graph()\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    vgg_layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    vgg_layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    vgg_layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "tests.test_load_vgg(load_vgg, tf) # This needs the 'variables' folder and saved_model.pb here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    # Regularizers and initializers\n",
    "    initializer = lambda: tf.truncated_normal_initializer(stddev=0.01)\n",
    "    regularizer = lambda: tf.contrib.layers.l2_regularizer(1e-5)\n",
    "    \n",
    "    # 1x1 convolution\n",
    "    layer7_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer7_out,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer7_out')\n",
    "    \n",
    "    \n",
    "    # Upsample\n",
    "    layer7_up = tf.layers.conv2d_transpose(\n",
    "    inputs=layer7_out,\n",
    "    filters=num_classes,\n",
    "    kernel_size=4,\n",
    "    strides=(2, 2),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer7_up')\n",
    "    \n",
    "    # Scaling of pooling layer 4\n",
    "    vgg_layer4_out_scaled = tf.multiply(vgg_layer4_out, 0.0001, name='vgg_layer4_out_scaled')\n",
    "    # 1x1 convolution\n",
    "    layer4_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer4_out_scaled,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer4_out')\n",
    "\n",
    "    # Skip layer\n",
    "    skip_1 = tf.add(layer7_up, layer4_out)\n",
    "\n",
    "    # Upsample\n",
    "    skip_1_up = tf.layers.conv2d_transpose(\n",
    "    inputs=skip_1,\n",
    "    filters=num_classes,\n",
    "    kernel_size=4,\n",
    "    strides=(2, 2),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'skip_1_up')\n",
    "    \n",
    "    # Scaling of pooling layer 3\n",
    "    vgg_layer3_out_scaled = tf.multiply(vgg_layer3_out, 0.0001, name='vgg_layer3_out_scaled')\n",
    "    # 1x1 convolution\n",
    "    layer3_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer3_out_scaled,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name='layer3_out')\n",
    "\n",
    "    # Skip layer\n",
    "    skip_2 = tf.add(skip_1_up, layer3_out)\n",
    "\n",
    "    # Upsampled final\n",
    "    nn_last_layer = tf.layers.conv2d_transpose(\n",
    "    inputs=skip_2,\n",
    "    filters=num_classes,\n",
    "    kernel_size=16,\n",
    "    strides=(8, 8),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name='nn_last_layer')\n",
    "    \n",
    "    return nn_last_layer\n",
    "tests.test_layers(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes), name='logits')\n",
    "    truth = tf.reshape(correct_label, (-1, num_classes))\n",
    "    predicts = tf.nn.softmax(logits, name='predicts')\n",
    "    #global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "    # Cross-entropy operation\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=truth)\n",
    "    cross_entropy_loss = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar('cross_entropy_loss', cross_entropy_loss)\n",
    "    \n",
    "    # Regularization loss\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    tf.summary.scalar('l2_loss', l2_loss)\n",
    "    \n",
    "    total_loss = cross_entropy_loss + l2_loss\n",
    "    tf.summary.scalar('total_loss', total_loss)\n",
    "    \n",
    "    #train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss, global_step)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n",
    "    \n",
    "    # Merge summary operation\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    return logits, train_op, cross_entropy_loss\n",
    "tests.test_optimize(optimize)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate,saver):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    min_epochs = 20\n",
    "    best_loss = 1e9\n",
    "    failure = 0\n",
    "    patience = 4\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        num_images = 0\n",
    "        sys.stdout.flush()\n",
    "        for images, labels in get_batches_fn(batch_size):\n",
    "            _, loss = sess.run([\n",
    "              train_op,\n",
    "              cross_entropy_loss], feed_dict={\n",
    "                  input_image: images,\n",
    "                  correct_label: labels,\n",
    "                  keep_prob: 0.5,\n",
    "                  learning_rate: 1e-4})\n",
    "            #writer.add_summary(summary, step)\n",
    "            epoch_loss += loss * len(images)\n",
    "            num_images += len(images)\n",
    "            \n",
    "        epoch_loss /= num_images\n",
    "        sys.stderr.flush()\n",
    "        print('Epoch {} loss: {:.3f}'.format(e + 1, epoch_loss))\n",
    "        if e >= min_epochs and epoch_loss > best_loss:\n",
    "          if failure == patience:\n",
    "            break\n",
    "          failure += 1\n",
    "        else:\n",
    "            failure = 0\n",
    "            best_loss = epoch_loss\n",
    "            print('Saving model')\n",
    "            saver.save(sess, './model.ckpt')\n",
    "    #pass\n",
    "#tests.test_train_nn(train_nn) #This one can be called if 'saver' is removed in train_nn call\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    num_classes = 2\n",
    "    image_shape = (160, 576)\n",
    "    data_dir = './data'\n",
    "    runs_dir = './runs'\n",
    "    tests.test_for_kitti_dataset(data_dir) # This will also download the kitti dataset, if not already there\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    epochs = 40\n",
    "    batch_size = 4\n",
    "\n",
    "    # Download pretrained vgg model\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "\n",
    "    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n",
    "    # You'll need a GPU with at least 10 teraFLOPS to train on.\n",
    "    #  https://www.cityscapes-dataset.com/\n",
    "    \n",
    "    #saver = tf.train.Saver()\n",
    "    #new_graph = tf.Graph()\n",
    "    #print(\"just before starting training\")\n",
    "    #input()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Path to vgg model\n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "        # Create function to get batches\n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape,augment=False)\n",
    "\n",
    "        # OPTIONAL: Augment Images for better results\n",
    "        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "\n",
    "        # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
    "        \n",
    "        nn_last_layer = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
    "        \n",
    "        logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # TODO: Train NN using the train_nn function\n",
    "        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate,saver)\n",
    "\n",
    "        # TODO: Save inference data using helper.save_inference_samples\n",
    "        helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n",
    "\n",
    "        # OPTIONAL: Apply the trained model to a video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0a3429af8f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-eb1beb020362>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# TODO: Build NN using load_vgg, layers, and optimize function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_layer3_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_layer4_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_layer7_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mnn_last_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_layer3_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_layer4_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_layer7_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-462aae6864ef>\u001b[0m in \u001b[0;36mload_vgg\u001b[0;34m(sess, vgg_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#   Use tf.saved_model.loader.load to load the model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvgg_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vgg16'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvgg_tag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvgg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvgg_input_tensor_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'image_input:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, **saver_kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;31m# Build a saver by importing the meta graph def to load.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_def_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m       \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saver_def\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_scope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscope_to_prepend_to_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         producer_op_list=producer_op_list)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# Restores all the other collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 instructions)\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    434\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mproducer_op_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;31m# TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0m_RemoveDefaultAttrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproducer_op_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_RemoveDefaultAttrs\u001b[0;34m(op_dict, producer_op_list, graph_def)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# We make a copy of node.attr to iterate through since we may modify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;31m# node.attr inside the loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_FindAttrInOpDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0;31m# No attr_def in consumer, look in producer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check output on a single image(Can run independently from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrices import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 576, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120bbffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PIXEL_MAX = 255\n",
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    \n",
    "    image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "    image_org = scipy.misc.imread(image_file)\n",
    "    image_resized = scipy.misc.imresize(image_org, image_shape) #This step is not required if image shape is already image_shape\n",
    "    image_resized = image_resized.reshape(1,*image_resized.shape)#Adds a dimension at the beginning\n",
    "    \n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "    \n",
    "    #predicted = predicted[0]\n",
    "    #im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    op_image = np.array(street_im)\n",
    "    print(np.shape(op_image))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(op_image)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image_org)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is another way to apply semantic segmentation on a single image(Almost same as the last one). Testing images are on testing folder and there is no ground truth for these images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_MAX = 255\n",
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "image_shape = (160, 576)\n",
    "\n",
    "feature_image_path = './data/data_road/testing/image_2/um_000003.png'\n",
    "\n",
    "feature_image = imageio.imread(feature_image_path)\n",
    "feature_copy = np.copy(feature_image)\n",
    "#scipy is used in helper.gen_batch_function() for reading and resizing images.\n",
    "feature_image = scipy.misc.imresize(feature_image, image_shape)\n",
    "feature_image = feature_image.reshape(1,*feature_image.shape)\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    predicted = sess.run([predicted], feed_dict={input_image: feature_image,keep_prob: 1.0})\n",
    "    #print(np.shape(predicted))\n",
    "    predicted = predicted[0]\n",
    "    \n",
    "    binary_road_result = (predicted[:, 0] > .5).reshape(image_shape)\n",
    "    binary_road_result = binary_road_result.astype('uint8')\n",
    "    \n",
    "binary_road_result = scipy.misc.imresize(binary_road_result, (375,1242))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,21))\n",
    "plt.subplot(211)\n",
    "plt.imshow(feature_copy)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(binary_road_result, cmap='gray')\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the graph to save as .pb file( saves the model as base_graph.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Model loaded\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    #tf.get_default_graph().as_graph_def()\n",
    "    graph_def = loaded_graph.as_graph_def() #current Graph as protobuffs\n",
    "    \n",
    "    # Parameters: 1) graph, 2) directory where we want to save the pb file,\n",
    "    #             3) name of the file, 4) text format (True) or binary format.\n",
    "    tf.train.write_graph(graph_def,\".\",\"base_graph.pb\",False)\n",
    "    \n",
    "\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow this link for details about freezing the graph etc\n",
    "https://stackoverflow.com/questions/45382917/how-to-optimize-for-inference-a-simple-saved-tensorflow-1-0-1-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this command in command window to freeze the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  python -m tensorflow.python.tools.freeze_graph --input_graph base_graph.pb --input_checkpoint model.ckpt --input_binary true --output_graph graph_frozen.pb --output_node_names=predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1764\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "from graph_utils import load_graph\n",
    "sess, base_ops = load_graph('base_graph.pb')\n",
    "print(len(base_ops)) # 2165\n",
    "\n",
    "#freeze graph by executing ./freeze_graph.sh\n",
    "sess, frozen_ops = load_graph('graph_frozen.pb') #Assuming that frozen_graph is created\n",
    "print(len(frozen_ops)) # 245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this command in command window to optimize for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### python -m tensorflow.python.tools.optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --frozen_graph True --input_names=image_input --output_names=predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "from graph_utils import load_graph\n",
    "\n",
    "sess, optimized_ops = load_graph('graph_optimized.pb')\n",
    "print(len(optimized_ops)) # 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python -m tensorflow.tools.graph_transforms.transform_graph.py --in_graph graph_frozen.pb out_graph=eightbit_graph.pb --inputs=image_input --outputs=predicts --transforms='\n",
    "add_default_attributes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "fuse_resize_and_conv\n",
    "quantize_weights\n",
    "quantize_nodes\n",
    "strip_unused_nodes\n",
    "sort_by_execution_order'\n",
    "\n",
    "This is still not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import load_graph\n",
    "\n",
    "sess, eightbit_ops = load_graph('eightbit_graph.pb')\n",
    "print(len(eightbit_ops)) # 425\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusing the graph for inference - approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This approach is not working\n",
    "import sys\n",
    "import time\n",
    "from scipy.misc import imread, imresize\n",
    "from glob import glob\n",
    "\n",
    "def load_graphh(graph_file, use_xla=False):\n",
    "    config = tf.ConfigProto()\n",
    "    if use_xla:\n",
    "        jit_level = tf.OptimizerOptions.ON_1\n",
    "        config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "\n",
    "    with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "        gd = tf.GraphDef()\n",
    "        with tf.gfile.Open(graph_file, 'rb') as f:\n",
    "            data = f.read()\n",
    "            gd.ParseFromString(data)\n",
    "        tf.import_graph_def(gd, name='')\n",
    "        ops = sess.graph.get_operations()\n",
    "        n_ops = len(ops)\n",
    "        print(\"Inside load_graphh\")\n",
    "        print(sess._closed)\n",
    "        return sess, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "d:\\users\\F65318A\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside load_graphh\n",
      "False\n",
      "True\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#from graph_utils import load_graph\n",
    "\n",
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "\n",
    "image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "image_resized = scipy.misc.imresize(image_org, image_shape) #This step is not required if image shape is already image_shape\n",
    "image_resized = image_resized.reshape(1,*image_resized.shape)#Adds a dimension at the beginning\n",
    "\n",
    "sess, _ = load_graphh('graph_frozen.pb')\n",
    "print(sess._closed) #status of the session\n",
    "#graph = sess1.graph\n",
    "#print(sess1._closed)\n",
    "\n",
    "#input_image = graph.get_tensor_by_name('image_input:0')\n",
    "#keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "#predicted = graph.get_tensor_by_name('predicts:0')\n",
    "\n",
    "#with tf.Session(graph=graph) as sess:\n",
    "#print(sess._closed)\n",
    "#im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "#print(sess._closed)\n",
    "'''\n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    \n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    op_image = np.array(street_im)\n",
    "    print(np.shape(op_image))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(op_image)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image_org)\n",
    "'''\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusing the graph for inference - approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above code does not work, trying different way\n",
    "import time\n",
    "from glob import glob\n",
    "def inference_images(data_dir, sess, image_shape, predicted, keep_prob, image_pl):\n",
    "    # Run NN on test images and save them to HD\n",
    "    print('Saving output images to: {}'.format(output_dir))\n",
    "    image_folder =os.path.join(data_dir, 'data_road/testing','image_2')\n",
    "    \n",
    "    for image_file in glob(os.path.join(image_folder, '*.png')):\n",
    "        image_resized = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "        image_resized = image_resized.reshape(1,*image_resized.shape)\n",
    "        \n",
    "        im_softmax = sess.run([predicted], feed_dict={image_pl: image_resized,keep_prob: 1.0})\n",
    "        \n",
    "        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "        mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "        #print(np.shape(mask))\n",
    "        #print(np.shape(image[0]))\n",
    "        street_im = scipy.misc.toimage(image_resized[0])\n",
    "        street_im.paste(mask, box=None, mask=mask)\n",
    "        \n",
    "        yield os.path.basename(image_file), np.array(street_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Saving output images to: ./runs_test/1542288827.614991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#This can be made a single script with name 'inference.py', for example\n",
    "image_shape = (160, 576)\n",
    "data_dir = './data_test'\n",
    "runs_dir = './runs_test'\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "use_xla=False\n",
    "config = tf.ConfigProto()\n",
    "if use_xla:\n",
    "    jit_level = tf.OptimizerOptions.ON_1\n",
    "    config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "    \n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    #ops = sess.graph.get_operations()\n",
    "    #n_ops = len(ops)\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    # Make folder for current run\n",
    "    output_dir = os.path.join(runs_dir, str(time.time()))\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    image_outputs = inference_images(data_dir, sess, image_shape, predicted, keep_prob, input_image)\n",
    "    \n",
    "    for name, image in image_outputs:\n",
    "        scipy.misc.imsave(os.path.join(output_dir, name), image)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fing IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(ground_truth, prediction, num_classes):\n",
    "    # TODO: Use `tf.metrics.mean_iou` to compute the mean IoU.\n",
    "    #iou, iou_op = None\n",
    "    iou, iou_op = tf.metrics.mean_iou(labels=ground_truth,predictions=prediction,num_classes=num_classes)\n",
    "    return iou, iou_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:27: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:27: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 92160, 2)\n",
      "(160, 576, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:50: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0e9b24a6a5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#What should be the dimensions of ground truth and prediction?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#iou, iou_op = mean_iou(ground_truth,prediction,num_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean IoU =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c9c5d9e28472>\u001b[0m in \u001b[0;36mmean_iou\u001b[0;34m(ground_truth, prediction, num_classes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# TODO: Use `tf.metrics.mean_iou` to compute the mean IoU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#iou, iou_op = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py\u001b[0m in \u001b[0;36mmean_iou\u001b[0;34m(labels, predictions, num_classes, weights, metrics_collections, updates_collections, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                                      (predictions, labels, weights)):\n\u001b[1;32m   1144\u001b[0m     \u001b[0;31m# Check if shape is compatible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     total_cm, update_op = _streaming_confusion_matrix(labels, predictions,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "num_classes = 2\n",
    "background_color = np.array([255, 0, 0])\n",
    "graph = tf.Graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    #Load saved model\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    \n",
    "    image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "    gt_image_file = os.path.join(data_dir, 'data_road/training/gt_image_2/um_lane_000000.png')\n",
    "    \n",
    "    image_resized = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "    image_resized = image_resized.reshape(1,*image_resized.shape)\n",
    "    \n",
    "    gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
    "    gt_image = gt_image.reshape(1,*gt_image.shape)\n",
    "    #print(np.shape(gt_image))\n",
    "    gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "    #print(np.shape(gt_bg))\n",
    "    gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "    #print(np.shape(gt_bg))\n",
    "    gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "    #print(np.shape(gt_image))\n",
    "    \n",
    "    im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "    print(np.shape(im_softmax))\n",
    "    #predicted = predicted[0]\n",
    "    #im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    print(np.shape(segmentation))\n",
    "    #print(np.shape(segmentation))\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    #What should be the dimensions of ground truth and prediction?\n",
    "    #iou, iou_op = mean_iou(ground_truth,prediction,num_classes)\n",
    "    iou, iou_op = mean_iou(gt_image,segmentation,num_classes)\n",
    "    sess.run(iou_op)\n",
    "    print(\"Mean IoU =\", sess.run(iou))\n",
    "    \n",
    "    #op_image = np.array(street_im)\n",
    "    #print(np.shape(op_image))\n",
    "    \n",
    "    #fig = plt.figure()\n",
    "    #plt.subplot(121)\n",
    "    #plt.imshow(op_image)\n",
    "    \n",
    "    #plt.subplot(122)\n",
    "    #plt.imshow(scipy.misc.imread(image_file))\n",
    "print(\"Done\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video : Model loaded from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_MAX = 255\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "def genn_output_image(sess, predicts, keep_prob, image_pl, input_image, image_shape):\n",
    "    #print(\"entered here\")\n",
    "    image_copy = np.copy(input_image)\n",
    "    \n",
    "    image = scipy.misc.imresize(input_image, image_shape)\n",
    "    image = image.reshape(1,*image.shape)#Adds a dimension at the beginning\n",
    "    \n",
    "    im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    #im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax[0][:, 1] > 0.5).reshape(image_shape)\n",
    "    segmentation = segmentation.astype('uint8')\n",
    "    \n",
    "    #segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "    \n",
    "    #At the beginning, I thought video frames are of same size as original training images, but are not, \n",
    "    #Video frames are of size (600,800), whereas original training images were of size (375, 1242)\n",
    "    #segmentation = scipy.misc.imresize(segmentation, (375,1242))\n",
    "    #segmentation = scipy.misc.imresize(segmentation, (600,800))\n",
    "    #The size of the resizing below really depends on the oroginal frame sizes in the video\n",
    "    segmentation = scipy.misc.imresize(segmentation, (720,1280))\n",
    "    \n",
    "    #mask = np.dot(segmentation.reshape(*segmentation.shape,1), np.array([[0, 255, 0, 127]]))\n",
    "    mask = np.dot(segmentation.reshape(*segmentation.shape,1), np.array([[PIXEL_MAX * .8, 0, 0]]))\n",
    "    #mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    p = image_copy + mask\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    #street_im = scipy.misc.toimage(image_copy[0])\n",
    "    #street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    p[p > PIXEL_MAX] = PIXEL_MAX\n",
    "    p = p.astype(np.uint8)\n",
    "    \n",
    "    #return np.array(street_im)\n",
    "    return p\n",
    "\n",
    "\n",
    "class MyVideoProcessor(object):\n",
    "    def __init__(self,sess,image_pl,keep_prob,predicted):\n",
    "        self.sess = sess\n",
    "        self.predicted=predicted\n",
    "        self.keep_prob=keep_prob\n",
    "        self.image_pl=image_pl\n",
    "        self.image_shape = (160, 576)\n",
    "        return\n",
    "    def pipeline(self, rgb_frame):\n",
    "        #print(np.shape(rgb_frame))\n",
    "        op_frame = genn_output_image(self.sess, self.predicted, self.keep_prob, self.image_pl, rgb_frame, self.image_shape)\n",
    "        return op_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Model loaded\n",
      "[MoviePy] >>>> Building video test_video_output.mp4\n",
      "[MoviePy] Writing video test_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [02:44<00:01,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_output.mp4 \n",
      "\n",
      "CPU times: user 8min 6s, sys: 37.6 s, total: 8min 44s\n",
      "Wall time: 2min 46s\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    my_video_processor_object = MyVideoProcessor(sess,input_image,keep_prob,predicted)\n",
    "    project_video_output = 'test_video_output.mp4'\n",
    "    clip = VideoFileClip(\"test_video.mp4\").subclip(0,4)\n",
    "    #clip = VideoFileClip(\"project_video.mp4\").subclip(0,4)\n",
    "    \n",
    "\n",
    "    white_clip = clip.fl_image(my_video_processor_object.pipeline) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(project_video_output, audio=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video:Approach 2, model loaded from optimized graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def generate_output_image(sess, predicts, keep_prob, image_pl, input_image, image_shape):\n",
    "    #print(\"entered here\")\n",
    "    image = scipy.misc.imresize(input_image, image_shape)\n",
    "    image = image.reshape(1,*image.shape)#Adds a dimension at the beginning\n",
    "    im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    return np.array(street_im)\n",
    "\n",
    "\n",
    "\n",
    "class MyVideoProcessor1(object):\n",
    "    def __init__(self,sess,image_pl,keep_prob,predicted):\n",
    "        self.sess = sess\n",
    "        self.predicted=predicted\n",
    "        self.keep_prob=keep_prob\n",
    "        self.image_pl=image_pl\n",
    "        self.image_shape = (160, 576)\n",
    "        return\n",
    "    def pipeline(self, rgb_frame):\n",
    "        op_frame = generate_output_image(self.sess, self.predicted, self.keep_prob, self.image_pl, rgb_frame, self.image_shape)\n",
    "        return op_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "[MoviePy] >>>> Building video test_video_output1.mp4\n",
      "[MoviePy] Writing video test_video_output1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [30:58<00:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_output1.mp4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 47min 25s, sys: 6min 6s, total: 1h 53min 32s\n",
      "Wall time: 30min 58s\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "use_xla=False\n",
    "config = tf.ConfigProto()\n",
    "if use_xla:\n",
    "    jit_level = tf.OptimizerOptions.ON_1\n",
    "    config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "    \n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    #ops = sess.graph.get_operations()\n",
    "    #n_ops = len(ops)\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    my_video_processor_object = MyVideoProcessor1(sess,input_image,keep_prob,predicted)\n",
    "    project_video_output = 'test_video_output1.mp4'\n",
    "    clip = VideoFileClip(\"test_video.mp4\")\n",
    "    \n",
    "    \n",
    "    white_clip = clip.fl_image(my_video_processor_object.pipeline) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(project_video_output, audio=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do: What if we want to calculate IOU on all training images(test images have no ground truth, so no IOU calculation possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
