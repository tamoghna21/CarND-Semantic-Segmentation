{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "from math import ceil\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: No GPU found. Please use a GPU to train your neural network.\n",
      "  import sys\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 1242, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 1242, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/um_000000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e3e1c52ffb1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#To check the shape of the output image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'um_000000.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_org\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_org\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/carnd-term1/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/um_000000.png'"
     ]
    }
   ],
   "source": [
    "#To check the shape of the output image\n",
    "image_file = os.path.join('runs', 'um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "print(np.shape(image_org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check the label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "background_color = np.array([255, 0, 0])\n",
    "\n",
    "image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "gt_image_file = os.path.join(data_dir, 'data_road/training/gt_image_2/um_lane_000000.png')\n",
    "\n",
    "image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
    "\n",
    "gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "print(np.shape(image))\n",
    "print(np.shape(gt_image))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.imshow(image)\n",
    "    \n",
    "plt.subplot(132)\n",
    "plt.imshow(gt_image[:,:,0],cmap='gray')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(gt_image[:,:,1],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here starts the actual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights\n",
    "    vgg_tag = 'vgg16'\n",
    "    tf.saved_model.loader.load(sess,[vgg_tag],vgg_path)\n",
    "    \n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    #graph = tf.Graph()\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    vgg_layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    vgg_layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    vgg_layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "tests.test_load_vgg(load_vgg, tf) # This needs the 'variables' folder and saved_model.pb here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    # Regularizers and initializers\n",
    "    initializer = lambda: tf.truncated_normal_initializer(stddev=0.01)\n",
    "    regularizer = lambda: tf.contrib.layers.l2_regularizer(1e-5)\n",
    "    \n",
    "    # 1x1 convolution\n",
    "    layer7_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer7_out,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer7_out')\n",
    "    \n",
    "    \n",
    "    # Upsample\n",
    "    layer7_up = tf.layers.conv2d_transpose(\n",
    "    inputs=layer7_out,\n",
    "    filters=num_classes,\n",
    "    kernel_size=4,\n",
    "    strides=(2, 2),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer7_up')\n",
    "    \n",
    "    # Scaling of pooling layer 4\n",
    "    vgg_layer4_out_scaled = tf.multiply(vgg_layer4_out, 0.0001, name='vgg_layer4_out_scaled')\n",
    "    # 1x1 convolution\n",
    "    layer4_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer4_out_scaled,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'layer4_out')\n",
    "\n",
    "    # Skip layer\n",
    "    skip_1 = tf.add(layer7_up, layer4_out)\n",
    "\n",
    "    # Upsample\n",
    "    skip_1_up = tf.layers.conv2d_transpose(\n",
    "    inputs=skip_1,\n",
    "    filters=num_classes,\n",
    "    kernel_size=4,\n",
    "    strides=(2, 2),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name = 'skip_1_up')\n",
    "    \n",
    "    # Scaling of pooling layer 3\n",
    "    vgg_layer3_out_scaled = tf.multiply(vgg_layer3_out, 0.0001, name='vgg_layer3_out_scaled')\n",
    "    # 1x1 convolution\n",
    "    layer3_out = tf.layers.conv2d(\n",
    "    inputs=vgg_layer3_out_scaled,\n",
    "    filters=num_classes,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name='layer3_out')\n",
    "\n",
    "    # Skip layer\n",
    "    skip_2 = tf.add(skip_1_up, layer3_out)\n",
    "\n",
    "    # Upsampled final\n",
    "    nn_last_layer = tf.layers.conv2d_transpose(\n",
    "    inputs=skip_2,\n",
    "    filters=num_classes,\n",
    "    kernel_size=16,\n",
    "    strides=(8, 8),\n",
    "    padding='same',\n",
    "    kernel_regularizer=regularizer(),\n",
    "    kernel_initializer=initializer(),\n",
    "    name='nn_last_layer')\n",
    "    \n",
    "    return nn_last_layer\n",
    "tests.test_layers(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes), name='logits')\n",
    "    truth = tf.reshape(correct_label, (-1, num_classes))\n",
    "    predicts = tf.nn.softmax(logits, name='predicts')\n",
    "    #global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "    # Cross-entropy operation\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=truth)\n",
    "    cross_entropy_loss = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar('cross_entropy_loss', cross_entropy_loss)\n",
    "    \n",
    "    # Regularization loss\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    tf.summary.scalar('l2_loss', l2_loss)\n",
    "    \n",
    "    total_loss = cross_entropy_loss + l2_loss\n",
    "    tf.summary.scalar('total_loss', total_loss)\n",
    "    \n",
    "    #train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss, global_step)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n",
    "    \n",
    "    # Merge summary operation\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    return logits, train_op, cross_entropy_loss\n",
    "tests.test_optimize(optimize)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate,saver):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    min_epochs = 20\n",
    "    best_loss = 1e9\n",
    "    failure = 0\n",
    "    patience = 4\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        num_images = 0\n",
    "        sys.stdout.flush()\n",
    "        for images, labels in get_batches_fn(batch_size):\n",
    "            _, loss = sess.run([\n",
    "              train_op,\n",
    "              cross_entropy_loss], feed_dict={\n",
    "                  input_image: images,\n",
    "                  correct_label: labels,\n",
    "                  keep_prob: 0.5,\n",
    "                  learning_rate: 1e-4})\n",
    "            #writer.add_summary(summary, step)\n",
    "            epoch_loss += loss * len(images)\n",
    "            num_images += len(images)\n",
    "            \n",
    "        epoch_loss /= num_images\n",
    "        sys.stderr.flush()\n",
    "        print('Epoch {} loss: {:.3f}'.format(e + 1, epoch_loss))\n",
    "        if e >= min_epochs and epoch_loss > best_loss:\n",
    "          if failure == patience:\n",
    "            break\n",
    "          failure += 1\n",
    "        else:\n",
    "            failure = 0\n",
    "            best_loss = epoch_loss\n",
    "            print('Saving model')\n",
    "            saver.save(sess, './model.ckpt')\n",
    "    #pass\n",
    "#tests.test_train_nn(train_nn) #This one can be called if 'saver' is removed in train_nn call\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    num_classes = 2\n",
    "    image_shape = (160, 576)\n",
    "    data_dir = './data'\n",
    "    runs_dir = './runs'\n",
    "    tests.test_for_kitti_dataset(data_dir) # This will also download the kitti dataset, if not already there\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    epochs = 40\n",
    "    batch_size = 4\n",
    "\n",
    "    # Download pretrained vgg model\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "\n",
    "    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n",
    "    # You'll need a GPU with at least 10 teraFLOPS to train on.\n",
    "    #  https://www.cityscapes-dataset.com/\n",
    "    \n",
    "    #saver = tf.train.Saver()\n",
    "    #new_graph = tf.Graph()\n",
    "    #print(\"just before starting training\")\n",
    "    #input()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Path to vgg model\n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "        # Create function to get batches\n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape,augment=False)\n",
    "\n",
    "        # OPTIONAL: Augment Images for better results\n",
    "        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "\n",
    "        # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
    "        \n",
    "        nn_last_layer = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
    "        \n",
    "        logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # TODO: Train NN using the train_nn function\n",
    "        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate,saver)\n",
    "\n",
    "        # TODO: Save inference data using helper.save_inference_samples\n",
    "        helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n",
    "\n",
    "        # OPTIONAL: Apply the trained model to a video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check output on a single image (Can run independently from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrices import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_MAX = 255\n",
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    \n",
    "    image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "    image_org = scipy.misc.imread(image_file)\n",
    "    image_resized = scipy.misc.imresize(image_org, image_shape) #This step is not required if image shape is already image_shape\n",
    "    image_resized = image_resized.reshape(1,*image_resized.shape)#Adds a dimension at the beginning\n",
    "    \n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "    \n",
    "    #predicted = predicted[0]\n",
    "    #im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    op_image = np.array(street_im)\n",
    "    print(np.shape(op_image))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(op_image)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image_org)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is another way to apply semantic segmentation on a single image(Almost same as the last one). Testing images are on testing folder and there is no ground truth for these images¶¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_MAX = 255\n",
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "image_shape = (160, 576)\n",
    "\n",
    "feature_image_path = './data/data_road/testing/image_2/um_000003.png'\n",
    "\n",
    "feature_image = imageio.imread(feature_image_path)\n",
    "feature_copy = np.copy(feature_image)\n",
    "#scipy is used in helper.gen_batch_function() for reading and resizing images.\n",
    "feature_image = scipy.misc.imresize(feature_image, image_shape)\n",
    "feature_image = feature_image.reshape(1,*feature_image.shape)\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    predicted = sess.run([predicted], feed_dict={input_image: feature_image,keep_prob: 1.0})\n",
    "    #print(np.shape(predicted))\n",
    "    predicted = predicted[0]\n",
    "    \n",
    "    binary_road_result = (predicted[:, 0] > .5).reshape(image_shape)\n",
    "    binary_road_result = binary_road_result.astype('uint8')\n",
    "    \n",
    "binary_road_result = scipy.misc.imresize(binary_road_result, (375,1242))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,21))\n",
    "plt.subplot(211)\n",
    "plt.imshow(feature_copy)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(binary_road_result, cmap='gray')\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the graph to save as .pb file (saves the model as base_graph.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    #tf.get_default_graph().as_graph_def()\n",
    "    graph_def = loaded_graph.as_graph_def() #current Graph as protobuffs\n",
    "    \n",
    "    # Parameters: 1) graph, 2) directory where we want to save the pb file,\n",
    "    #             3) name of the file, 4) text format (True) or binary format.\n",
    "    tf.train.write_graph(graph_def,\".\",\"base_graph.pb\",False)\n",
    "    \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow this link for details about freezing the graph etc\n",
    "https://stackoverflow.com/questions/45382917/how-to-optimize-for-inference-a-simple-saved-tensorflow-1-0-1-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this command in command window to freeze the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  python -m tensorflow.python.tools.freeze_graph --input_graph base_graph.pb --input_checkpoint model.ckpt --input_binary true --output_graph graph_frozen.pb --output_node_names=predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import load_graph\n",
    "sess, base_ops = load_graph('base_graph.pb')\n",
    "print(len(base_ops)) # 2165\n",
    "\n",
    "#freeze graph by executing ./freeze_graph.sh\n",
    "sess, frozen_ops = load_graph('graph_frozen.pb') #Assuming that frozen_graph is created\n",
    "print(len(frozen_ops)) # 245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this command in command window to optimize for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### python -m tensorflow.python.tools.optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --frozen_graph True --input_names=image_input --output_names=predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import load_graph\n",
    "\n",
    "sess, optimized_ops = load_graph('graph_optimized.pb')\n",
    "print(len(optimized_ops)) # 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python -m tensorflow.tools.graph_transforms.transform_graph.py --in_graph graph_frozen.pb out_graph=eightbit_graph.pb --inputs=image_input --outputs=predicts --transforms='\n",
    "add_default_attributes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "fuse_resize_and_conv\n",
    "quantize_weights\n",
    "quantize_nodes\n",
    "strip_unused_nodes\n",
    "sort_by_execution_order'\n",
    "\n",
    "This is still not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import load_graph\n",
    "\n",
    "sess, eightbit_ops = load_graph('eightbit_graph.pb')\n",
    "print(len(eightbit_ops)) # 425\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusing the graph for inference - approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This approach is not working\n",
    "import sys\n",
    "import time\n",
    "from scipy.misc import imread, imresize\n",
    "from glob import glob\n",
    "\n",
    "def load_graphh(graph_file, use_xla=False):\n",
    "    config = tf.ConfigProto()\n",
    "    if use_xla:\n",
    "        jit_level = tf.OptimizerOptions.ON_1\n",
    "        config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "\n",
    "    with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "        gd = tf.GraphDef()\n",
    "        with tf.gfile.Open(graph_file, 'rb') as f:\n",
    "            data = f.read()\n",
    "            gd.ParseFromString(data)\n",
    "        tf.import_graph_def(gd, name='')\n",
    "        ops = sess.graph.get_operations()\n",
    "        n_ops = len(ops)\n",
    "        print(\"Inside load_graphh\")\n",
    "        print(sess._closed)\n",
    "        return sess, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from graph_utils import load_graph\n",
    "\n",
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "\n",
    "image_file = os.path.join(data_dir, 'data_road/testing/image_2/um_000000.png')\n",
    "image_org = scipy.misc.imread(image_file)\n",
    "image_resized = scipy.misc.imresize(image_org, image_shape) #This step is not required if image shape is already image_shape\n",
    "image_resized = image_resized.reshape(1,*image_resized.shape)#Adds a dimension at the beginning\n",
    "\n",
    "sess, _ = load_graphh('graph_frozen.pb')\n",
    "print(sess._closed) #status of the session\n",
    "#graph = sess1.graph\n",
    "#print(sess1._closed)\n",
    "\n",
    "#input_image = graph.get_tensor_by_name('image_input:0')\n",
    "#keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "#predicted = graph.get_tensor_by_name('predicts:0')\n",
    "\n",
    "#with tf.Session(graph=graph) as sess:\n",
    "#print(sess._closed)\n",
    "#im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "#print(sess._closed)\n",
    "'''\n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    \n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    op_image = np.array(street_im)\n",
    "    print(np.shape(op_image))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(op_image)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image_org)\n",
    "'''\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusing the graph for inference - approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above code does not work, trying different way\n",
    "import time\n",
    "from glob import glob\n",
    "def inference_images(data_dir, sess, image_shape, predicted, keep_prob, image_pl):\n",
    "    # Run NN on test images and save them to HD\n",
    "    print('Saving output images to: {}'.format(output_dir))\n",
    "    image_folder =os.path.join(data_dir, 'data_road/testing','image_2')\n",
    "    \n",
    "    for image_file in glob(os.path.join(image_folder, '*.png')):\n",
    "        image_resized = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "        image_resized = image_resized.reshape(1,*image_resized.shape)\n",
    "        \n",
    "        im_softmax = sess.run([predicted], feed_dict={image_pl: image_resized,keep_prob: 1.0})\n",
    "        \n",
    "        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "        mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "        #print(np.shape(mask))\n",
    "        #print(np.shape(image[0]))\n",
    "        street_im = scipy.misc.toimage(image_resized[0])\n",
    "        street_im.paste(mask, box=None, mask=mask)\n",
    "        \n",
    "        yield os.path.basename(image_file), np.array(street_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can be made a single script with name 'inference.py', for example\n",
    "image_shape = (160, 576)\n",
    "data_dir = './data_test'\n",
    "runs_dir = './runs_test'\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "use_xla=False\n",
    "config = tf.ConfigProto()\n",
    "if use_xla:\n",
    "    jit_level = tf.OptimizerOptions.ON_1\n",
    "    config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "    \n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    #ops = sess.graph.get_operations()\n",
    "    #n_ops = len(ops)\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    # Make folder for current run\n",
    "    output_dir = os.path.join(runs_dir, str(time.time()))\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    image_outputs = inference_images(data_dir, sess, image_shape, predicted, keep_prob, input_image)\n",
    "    \n",
    "    for name, image in image_outputs:\n",
    "        scipy.misc.imsave(os.path.join(output_dir, name), image)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fing IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(ground_truth, prediction, num_classes):\n",
    "    # TODO: Use `tf.metrics.mean_iou` to compute the mean IoU.\n",
    "    #iou, iou_op = None\n",
    "    iou, iou_op = tf.metrics.mean_iou(labels=ground_truth,predictions=prediction,num_classes=num_classes)\n",
    "    return iou, iou_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "image_shape = (160, 576)\n",
    "num_classes = 2\n",
    "background_color = np.array([255, 0, 0])\n",
    "graph = tf.Graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    #Load saved model\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    \n",
    "    image_file = os.path.join(data_dir, 'data_road/training/image_2/um_000000.png')\n",
    "    gt_image_file = os.path.join(data_dir, 'data_road/training/gt_image_2/um_lane_000000.png')\n",
    "    \n",
    "    image_resized = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "    image_resized = image_resized.reshape(1,*image_resized.shape)\n",
    "    \n",
    "    gt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
    "    gt_image = gt_image.reshape(1,*gt_image.shape)\n",
    "    #print(np.shape(gt_image))\n",
    "    gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "    #print(np.shape(gt_bg))\n",
    "    gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "    #print(np.shape(gt_bg))\n",
    "    gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "    #print(np.shape(gt_image))\n",
    "    \n",
    "    im_softmax = sess.run([predicted], feed_dict={input_image: image_resized,keep_prob: 1.0})\n",
    "    print(np.shape(im_softmax))\n",
    "    #predicted = predicted[0]\n",
    "    #im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    print(np.shape(segmentation))\n",
    "    #print(np.shape(segmentation))\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image_resized[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    #What should be the dimensions of ground truth and prediction?\n",
    "    #iou, iou_op = mean_iou(ground_truth,prediction,num_classes)\n",
    "    iou, iou_op = mean_iou(gt_image,segmentation,num_classes)\n",
    "    sess.run(iou_op)\n",
    "    print(\"Mean IoU =\", sess.run(iou))\n",
    "    \n",
    "    #op_image = np.array(street_im)\n",
    "    #print(np.shape(op_image))\n",
    "    \n",
    "    #fig = plt.figure()\n",
    "    #plt.subplot(121)\n",
    "    #plt.imshow(op_image)\n",
    "    \n",
    "    #plt.subplot(122)\n",
    "    #plt.imshow(scipy.misc.imread(image_file))\n",
    "print(\"Done\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video : Model loaded from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "def genn_output_image(sess, predicts, keep_prob, image_pl, input_image, image_shape):\n",
    "    #print(\"entered here\")\n",
    "    image = scipy.misc.imresize(input_image, image_shape)\n",
    "    image = image.reshape(1,*image.shape)#Adds a dimension at the beginning\n",
    "    im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    return np.array(street_im)\n",
    "\n",
    "\n",
    "class MyVideoProcessor(object):\n",
    "    def __init__(self,sess,image_pl,keep_prob,predicted):\n",
    "        self.sess = sess\n",
    "        self.predicted=predicted\n",
    "        self.keep_prob=keep_prob\n",
    "        self.image_pl=image_pl\n",
    "        self.image_shape = (160, 576)\n",
    "        return\n",
    "    def pipeline(self, rgb_frame):\n",
    "        op_frame = genn_output_image(self.sess, self.predicted, self.keep_prob, self.image_pl, rgb_frame, self.image_shape)\n",
    "        return op_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b08b50b6740c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mload_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./model.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaded_graph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Load saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    my_video_processor_object = MyVideoProcessor(sess,input_image,keep_prob,predicted)\n",
    "    project_video_output = 'test_video_output.mp4'\n",
    "    clip = VideoFileClip(\"test_video.mp4\")\n",
    "    #clip = VideoFileClip(\"project_video.mp4\").subclip(0,4)\n",
    "    \n",
    "\n",
    "    white_clip = clip.fl_image(my_video_processor_object.pipeline) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(project_video_output, audio=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project_video_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6aea48f6b5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"<video width=\"960\" height=\"540\" controls><source src=\"{0}\"></video>\"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_video_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'project_video_output' is not defined"
     ]
    }
   ],
   "source": [
    "HTML(\"\"\"<video width=\"960\" height=\"540\" controls><source src=\"{0}\"></video>\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video : Model loaded from checkpoint(Another way of masking and overlaying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_MAX = 255\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "def genn_output_image(sess, predicts, keep_prob, image_pl, input_image, image_shape):\n",
    "    #print(\"entered here\")\n",
    "    image_copy = np.copy(input_image)\n",
    "    \n",
    "    image = scipy.misc.imresize(input_image, image_shape)\n",
    "    image = image.reshape(1,*image.shape)#Adds a dimension at the beginning\n",
    "    \n",
    "    im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    #im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax[0][:, 1] > 0.5).reshape(image_shape)\n",
    "    segmentation = segmentation.astype('uint8')\n",
    "    \n",
    "    #segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    \n",
    "    \n",
    "    #At the beginning, I thought video frames are of same size as original training images, but are not, \n",
    "    #Video frames are of size (600,800), whereas original training images were of size (375, 1242)\n",
    "    #segmentation = scipy.misc.imresize(segmentation, (375,1242))\n",
    "    #segmentation = scipy.misc.imresize(segmentation, (600,800))\n",
    "    #The size of the resizing below really depends on the oroginal frame sizes in the video\n",
    "    segmentation = scipy.misc.imresize(segmentation, (720,1280))\n",
    "    \n",
    "   \n",
    "    mask = np.dot(segmentation.reshape(*segmentation.shape,1), np.array([[PIXEL_MAX * .8, 0, 0]]))\n",
    "    #mask = np.dot(segmentation.reshape(*segmentation.shape,1), np.array([[127, 0, 0]]))\n",
    "    #mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    p = image_copy + mask\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    #street_im = scipy.misc.toimage(image_copy[0])\n",
    "    #street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    p[p > PIXEL_MAX] = PIXEL_MAX\n",
    "    p = p.astype(np.uint8)\n",
    "    \n",
    "    #return np.array(street_im)\n",
    "    return p\n",
    "\n",
    "\n",
    "class MyVideoProcessor(object):\n",
    "    def __init__(self,sess,image_pl,keep_prob,predicted):\n",
    "        self.sess = sess\n",
    "        self.predicted=predicted\n",
    "        self.keep_prob=keep_prob\n",
    "        self.image_pl=image_pl\n",
    "        self.image_shape = (160, 576)\n",
    "        return\n",
    "    def pipeline(self, rgb_frame):\n",
    "        #print(np.shape(rgb_frame))\n",
    "        op_frame = genn_output_image(self.sess, self.predicted, self.keep_prob, self.image_pl, rgb_frame, self.image_shape)\n",
    "        return op_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "load_dir = './model.ckpt'\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    #Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Gather required tensor references\n",
    "    input_image = loaded_graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = loaded_graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    my_video_processor_object = MyVideoProcessor(sess,input_image,keep_prob,predicted)\n",
    "    project_video_output = 'test_video_output_another_way.mp4'\n",
    "    clip = VideoFileClip(\"test_video.mp4\").subclip(0,4)\n",
    "    #clip = VideoFileClip(\"project_video.mp4\").subclip(0,4)\n",
    "    \n",
    "\n",
    "    white_clip = clip.fl_image(my_video_processor_object.pipeline) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(project_video_output, audio=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video:Approach 2, model loaded from optimized graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def generate_output_image(sess, predicts, keep_prob, image_pl, input_image, image_shape):\n",
    "    #print(\"entered here\")\n",
    "    image = scipy.misc.imresize(input_image, image_shape)\n",
    "    image = image.reshape(1,*image.shape)#Adds a dimension at the beginning\n",
    "    im_softmax = sess.run([predicts],feed_dict={image_pl: image,keep_prob: 1.0})\n",
    "    \n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    #print(np.shape(mask))\n",
    "    #print(np.shape(image[0]))\n",
    "    street_im = scipy.misc.toimage(image[0])\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "    \n",
    "    return np.array(street_im)\n",
    "\n",
    "\n",
    "\n",
    "class MyVideoProcessor1(object):\n",
    "    def __init__(self,sess,image_pl,keep_prob,predicted):\n",
    "        self.sess = sess\n",
    "        self.predicted=predicted\n",
    "        self.keep_prob=keep_prob\n",
    "        self.image_pl=image_pl\n",
    "        self.image_shape = (160, 576)\n",
    "        return\n",
    "    def pipeline(self, rgb_frame):\n",
    "        op_frame = generate_output_image(self.sess, self.predicted, self.keep_prob, self.image_pl, rgb_frame, self.image_shape)\n",
    "        return op_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "use_xla=False\n",
    "config = tf.ConfigProto()\n",
    "if use_xla:\n",
    "    jit_level = tf.OptimizerOptions.ON_1\n",
    "    config.graph_options.optimizer_options.global_jit_level = jit_level\n",
    "    \n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open('graph_optimized.pb', 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    #ops = sess.graph.get_operations()\n",
    "    #n_ops = len(ops)\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    input_image = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    predicted = graph.get_tensor_by_name('predicts:0')\n",
    "    \n",
    "    my_video_processor_object = MyVideoProcessor1(sess,input_image,keep_prob,predicted)\n",
    "    project_video_output = 'test_video_output1.mp4'\n",
    "    clip = VideoFileClip(\"test_video.mp4\")\n",
    "    \n",
    "    \n",
    "    white_clip = clip.fl_image(my_video_processor_object.pipeline) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(project_video_output, audio=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do: What if we want to calculate IOU on all training images(test images have no ground truth, so no IOU calculation possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
